# ğŸ›¡ï¸ AI Trust Forensics Platform v2.2

> **Detecting, proving, and explaining adversarial data poisoning attacks on AI/ML systems â€” in real time.**

[![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green?logo=fastapi)](https://fastapi.tiangolo.com)
[![React](https://img.shields.io/badge/React-18+-61DAFB?logo=react)](https://react.dev)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

---

## ğŸ¯ What is this?

**Data poisoning** is when an attacker secretly injects malicious training samples into an AI model's dataset. The model trains normally, passes all standard tests, gets deployed â€” and then silently causes harm. Our platform detects these attacks using a 5-layer forensic pipeline, proves the harm causally, and generates regulatory evidence.

Built for the **Sustainable Development Goals (SDG) Hackathon** â€” specifically targeting SDG 3 (Good Health), SDG 9 (Infrastructure), and SDG 16 (Strong Institutions).

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| **5-Layer Detection Pipeline** | Statistical shift â†’ Spectral activation â†’ Ensemble anomaly â†’ Causal proof â†’ Federated trust |
| **Attack Type Classification** | Automatically identifies: label flip, backdoor, clean label, gradient poisoning, boiling frog |
| **Causal Proof Engine** | Mathematically *proves* harm using counterfactual analysis, bootstrap CI, and placebo tests |
| **Model Scanner** | Upload `.pkl` scikit-learn models and scan their parameters for signs of poisoning |
| **Real Dataset Library** | Iris, Wine, Breast Cancer, Digits â€” with known-quantity poison injection for ground-truth validation |
| **SQLite Persistence** | All analysis results stored permanently and queryable via the History page |
| **Red Team Simulator** | Inject synthetic attacks and measure the platform's resilience in real time |
| **Blue Team SOC** | Security Operations Centre â€” threat level, HITL review queue, incident log, response playbooks |
| **Federated Trust** | Cosine similarity + EMA trust scoring for federated learning client safety |
| **Regulatory Reports** | NIST AI RMF and EU AI Act compliant evidence packages |
| **Live WebSocket Feed** | Real-time event streaming for attack confirmations and defense actions |

---

## ğŸ—ï¸ Architecture

```
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ detection/          # 5-layer detection pipeline
â”‚       â”‚   â”œâ”€â”€ layer1_statistical.py   # KL Divergence, Wasserstein, Mahalanobis
â”‚       â”‚   â”œâ”€â”€ layer2_spectral.py      # SVD spectral gap + KMeans backdoor detection
â”‚       â”‚   â”œâ”€â”€ layer3_ensemble.py      # IsolationForest + SVM + LOF + DBSCAN voting
â”‚       â”‚   â”œâ”€â”€ layer4_causal.py        # Counterfactual causal proof engine
â”‚       â”‚   â””â”€â”€ layer5_federated.py     # Cosine similarity + EMA trust scoring
â”‚       â”œâ”€â”€ forensics/          # Attack reconstruction + narratives
â”‚       â”œâ”€â”€ defense/            # Auto-defense + HITL + Red Team
â”‚       â”œâ”€â”€ ingestion/          # CSV + Model (.pkl) parsing
â”‚       â”œâ”€â”€ demo/               # Synthetic + real public datasets
â”‚       â”œâ”€â”€ db/                 # SQLite persistence layer
â”‚       â””â”€â”€ api/routes.py       # 29 REST endpoints + WebSocket
â”‚
â””â”€â”€ frontend/
    â””â”€â”€ src/
        â””â”€â”€ pages/
            â”œâ”€â”€ Dashboard.jsx         # Live trust scores + radar chart
            â”œâ”€â”€ UploadPage.jsx        # Upload and analyse CSV files
            â”œâ”€â”€ ModelScanPage.jsx     # Scan .pkl models
            â”œâ”€â”€ RealDatasetsPage.jsx  # Real dataset library
            â”œâ”€â”€ ForensicsPage.jsx     # Attack reconstruction details
            â”œâ”€â”€ RedTeamPage.jsx       # Attack simulation
            â”œâ”€â”€ BlueTeamPage.jsx      # SOC â€” defense operations
            â”œâ”€â”€ FederatedPage.jsx     # Federated client trust
            â”œâ”€â”€ ReportsPage.jsx       # Regulatory evidence reports
            â””â”€â”€ HistoryPage.jsx       # Past analysis results
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+

### Backend

```bash
cd backend

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Start the server
uvicorn app.main:app --port 8001 --reload
```

The backend runs at `http://localhost:8001` â€” API docs at `http://localhost:8001/docs`

### Frontend

```bash
cd frontend

# Install dependencies
npm install

# Start the dev server
npm run dev
```

The frontend runs at `http://localhost:5173`

---

## ğŸ”¬ The 5-Layer Detection Pipeline

### Layer 1 â€” Statistical Shift Detection
Compares incoming data distribution to a clean baseline using:
- **KL Divergence** â€” information-theoretic distribution distance
- **Wasserstein Distance** â€” earth mover's distance between distributions
- **Mahalanobis Distance** â€” multivariate outlier detection accounting for feature correlations

### Layer 2 â€” Spectral Activation Analysis
Detects backdoor attacks via SVD (Singular Value Decomposition):
- A large **spectral gap** (Sâ‚€/Sâ‚ ratio) indicates a backdoor subspace
- **KMeans** on PCA-reduced activations finds the trigger cluster

### Layer 3 â€” Ensemble Anomaly Detection
Four algorithms vote on each sample (â‰¥2 votes = flagged):
- Isolation Forest Â· SGD One-Class SVM Â· Local Outlier Factor Â· DBSCAN

### Layer 4 â€” Causal Proof Engine
Inspired by Judea Pearl's Do-Calculus:
```
Causal Effect = Accuracy(without suspects) âˆ’ Accuracy(with suspects)
```
Validated with: bootstrap 95% CI, placebo test, t-test (p < 0.05)

### Layer 5 â€” Federated Behavioral Trust
- Cosine similarity between client gradients and global gradient
- EMA trust score per client (Î± = 0.1)
- Auto-quarantine below 0.3 trust threshold

---

## ğŸ“¡ API Endpoints (Selected)

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/demo/run` | Run full analysis on demo data |
| `POST` | `/api/v1/analyze/upload` | Upload and analyse a CSV |
| `POST` | `/api/v1/analyze/model` | Scan a `.pkl` model file |
| `GET` | `/api/v1/datasets/real` | Real dataset catalog |
| `POST` | `/api/v1/redteam/simulate` | Inject attack + measure detection |
| `GET` | `/api/v1/blueteam/status` | SOC threat level + summary |
| `GET` | `/api/v1/blueteam/resilience` | Per-attack catch rate metrics |
| `GET` | `/api/v1/blueteam/playbook/{type}` | Incident response playbook |
| `GET` | `/api/v1/history` | SQLite-backed analysis history |
| `WS` | `/ws/v1/detection-stream` | Real-time event stream |

Full API docs: `http://localhost:8001/docs`

---

## ğŸŒ SDG Alignment

| SDG | Connection |
|-----|-----------|
| **SDG 3** â€” Good Health & Well-being | Prevents poisoned medical diagnostic AI from harming patients |
| **SDG 9** â€” Industry & Infrastructure | Provides security infrastructure for trustworthy AI deployment |
| **SDG 16** â€” Peace, Justice & Strong Institutions | Ensures AI used in governance/justice is tamper-proof |
| **SDG 17** â€” Partnerships | Secures federated learning between institutions without sharing raw data |

---

## ğŸ›¡ï¸ Security

The model scanner uses **pre-execution opcode scanning** â€” suspicious `.pkl` files are scanned at the bytecode level before any code executes. Only whitelisted scikit-learn classes are allowed.

---

## ğŸ“‹ Tech Stack

| Layer | Technology |
|-------|-----------|
| Backend | Python 3.10, FastAPI, Uvicorn |
| ML/Science | NumPy, SciPy, scikit-learn |
| Database | SQLite (WAL mode, thread-local connections) |
| Frontend | React 18, Vite, Tailwind CSS |
| Charts | Recharts |
| Icons | Lucide React |
| Real-time | WebSocket (native) |

---

## ğŸ“„ License

MIT â€” see [LICENSE](LICENSE)

---

Built with â¤ï¸ for the Hackathon | AI Trust Forensics Platform v2.2
